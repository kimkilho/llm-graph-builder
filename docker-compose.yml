version: "3"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    volumes:
      - ./backend:/code
    env_file:
      - ./backend/.env
    container_name: backend
    extra_hosts:
      - host.docker.internal:host-gateway
    ports:
      - "8000:8000"
    networks:
      - net

  frontend:
    depends_on:
      - backend
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - VITE_BACKEND_API_URL=${VITE_BACKEND_API_URL-http://localhost:8000}
        - VITE_REACT_APP_SOURCES=${VITE_REACT_APP_SOURCES-local,youtube,wiki,s3,web}
        - VITE_GOOGLE_CLIENT_ID=${VITE_GOOGLE_CLIENT_ID-}
        - VITE_BLOOM_URL=${VITE_BLOOM_URL-https://workspace-preview.neo4j.io/workspace/explore?connectURL={CONNECT_URL}&search=Show+me+a+graph&featureGenAISuggestions=true&featureGenAISuggestionsInternal=true}
        - VITE_TIME_PER_PAGE=${VITE_TIME_PER_PAGE-50}
        - VITE_CHUNK_SIZE=${VITE_CHUNK_SIZE-5242880}
        - VITE_LARGE_FILE_SIZE=${VITE_LARGE_FILE_SIZE-5242880}
        - VITE_ENV=${VITE_ENV-DEV}
        - VITE_CHAT_MODES=${VITE_CHAT_MODES-}
        - VITE_BATCH_SIZE=${VITE_BATCH_SIZE-2}
        - VITE_LLM_MODELS=${VITE_LLM_MODELS-openai_gpt_4.1,openai_gpt_4.1_mini}
        - VITE_LLM_MODELS_PROD=${VITE_LLM_MODELS_PROD-openai_gpt_4.1,openai_gpt_4.1_mini}
        - VITE_AUTH0_DOMAIN=${VITE_AUTH0_DOMAIN-}
        - VITE_AUTH0_CLIENT_ID=${VITE_AUTH0_CLIENT_ID-}
        - VITE_SKIP_AUTH=${VITE_SKIP_AUTH-true}
        - VITE_CHUNK_OVERLAP=${VITE_CHUNK_OVERLAP-}
        - VITE_TOKENS_PER_CHUNK=${VITE_TOKENS_PER_CHUNK-}
        - VITE_CHUNK_TO_COMBINE=${VITE_CHUNK_TO_COMBINE-}
        - DEPLOYMENT_ENV=local
    volumes:
      - ./frontend:/app
      - /app/node_modules
    env_file:
      - ./frontend/.env
    container_name: frontend
    ports:
      - "8080:8080"
    networks:
      - net

networks:
  net:
